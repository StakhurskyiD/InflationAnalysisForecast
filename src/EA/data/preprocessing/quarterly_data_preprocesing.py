#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
preprocess_quarterly.py
~~~~~~~~~~~~~~~~~~~~~~~
–ê–∫—É—Ä–∞—Ç–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è/–∑–±–∞–≥–∞—á–µ–Ω–Ω—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏—Ö CSV –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—é –≤—Ç—Ä–∞—Ç–æ—é —Ä—è–¥–∫—ñ–≤.

–û—Å–Ω–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ
------------------
‚Ä¢ auto-mapping –∫–æ–ª–æ–Ω–æ–∫ (quarterly_columns_map)
‚Ä¢ clean-numeric  ‚Üí float
‚Ä¢ winsorize (IQR-clip) üîÑ off/on
‚Ä¢ forward/back fill –ø—Ä–æ–ø—É—Å–∫—ñ–≤
‚Ä¢ —Å–µ–∑–æ–Ω-adjust (statsmodels) üîÑ off/on
‚Ä¢ ADF-—Ç–µ—Å—Ç + json-summary
‚Ä¢ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è:         research_data/preprocessed_data/processed_quarterly_data.csv
"""

from __future__ import annotations
import argparse, json, os, re
from pathlib import Path

import numpy as np
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PROJECT PATHS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
ROOT = Path(__file__).resolve().parents[3]
RAW_DIR = ROOT / "research_data" / "import_data"
OUT_DIR = ROOT / "research_data" / "preprocessed_data"
OUT_DIR.mkdir(parents=True, exist_ok=True)

RAW_FILE = RAW_DIR / "imported_quarterly_data.csv"
OUT_FILE = OUT_DIR / "processed_quarterly_data.csv"
STAT_FILE = OUT_DIR / "stats.json"

# ---- –∫–æ–ª–æ–Ω–∫–æ–≤–∏–π —Å–ª–æ–≤–Ω–∏—á–æ–∫
from src.EA.data.mapping.column_mappings import quarterly_columns_map  # noqa


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HELPERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
def clean_numeric(x: str | float | int) -> float | np.nan:
    s = str(x).strip()
    if ',' in s and '.' not in s:
        s = s.replace(',', '.')
    s = re.sub(r"[^\d\.\-]", "", s)
    return float(s) if s else np.nan


def winsorize_iqr(s: pd.Series, k: float = 1.5) -> pd.Series:
    q1, q3 = s.quantile([.25, .75])
    lo, hi = q1 - k * (q3 - q1), q3 + k * (q3 - q1)
    return s.clip(lo, hi)


def seasonal_adjust(ts: pd.Series, period: int = 4,
                    model: str = "additive") -> pd.Series:
    if ts.dropna().shape[0] < period * 2:
        print(f"[SA] Not enough points for {ts.name} ‚Äì skipped")
        return ts  # –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —è–∫ —î
    res = seasonal_decompose(ts, model=model, period=period,
                             extrapolate_trend='freq')
    return ts - res.seasonal if model == "additive" else ts / res.seasonal


def adf_pvalue(s: pd.Series) -> float:
    s = s.dropna()
    return np.nan if s.empty else adfuller(s)[1]


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MAIN PIPELINE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
def preprocess_quarterly_data(
    raw_file: Path = RAW_FILE,
    out_file: Path = OUT_FILE,
    do_winsor: bool = True,
    do_seasonal: bool = True,
    row_thresh: float = .7,
) -> None:

    # 0 ‚îÄ load & map
    df = pd.read_csv(raw_file, dtype=str).rename(columns=quarterly_columns_map)

    # 1 ‚îÄ duplicates
    before_dup = len(df)
    df = df.drop_duplicates()
    print(f"Duplicates removed: {before_dup - len(df)}")

    # 2 ‚îÄ tidy numeric
    num_cols = df.columns.difference(["quarter_period", "date"])
    df[num_cols] = (df[num_cols]
                    .applymap(clean_numeric)
                    .astype(float))

    # 3 ‚îÄ add date if absent
    if "date" not in df.columns:
        df["quarter_period"] = df["quarter_period"].str.replace(" ", "")
        df["date"] = pd.PeriodIndex(df["quarter_period"], freq="Q").to_timestamp("s")

    # 4 ‚îÄ winsorize
    if do_winsor:
        df[num_cols] = df[num_cols].apply(winsorize_iqr)

    # 5 ‚îÄ forward + back fill light gaps
    df = df.sort_values("date").set_index("date")
    df[num_cols] = df[num_cols].ffill().bfill()

    # 6 ‚îÄ drop *very* sparse rows
    keep = df.notna().mean(1) >= row_thresh
    removed = (~keep).sum()
    df = df[keep]
    print(f"Rows dropped by sparsity threshold ({row_thresh*100:.0f}%): {removed}")

    # 7 ‚îÄ seasonal adjust selected columns
    sa_col = "real_gdp_index"
    if do_seasonal and sa_col in df.columns:
        df[f"{sa_col}_sa"] = seasonal_adjust(df[sa_col], period=4)

    # 8 ‚îÄ ADF test (–∑–±–µ—Ä—ñ–≥–∞—î–º–æ p-values)
    stats = {}
    for col in [sa_col, f"{sa_col}_sa"] if f"{sa_col}_sa" in df.columns else [sa_col]:
        stats[f"adf_p_{col}"] = adf_pvalue(df[col])

    # 9 ‚îÄ save
    df.reset_index().to_csv(out_file, index=False)
    json.dump(stats, open(STAT_FILE, "w"), indent=2)

    print(f"‚úì Saved {len(df)} rows ‚Üí {out_file.name}")
    print(f"   Stats written ‚Üí {STAT_FILE.name}")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
def load_and_map_quarterly_data():
    p = argparse.ArgumentParser()
    p.add_argument("--winsor",  action="store_true", default=False,
                   help="clip outliers via IQR instead of leaving raw")
    p.add_argument("--no-seasonal", action="store_true", default=False,
                   help="skip seasonal adjustment step")
    p.add_argument("--row-thresh", type=float, default=.7,
                   help="min share of non-NaN per row to keep (0-1)")
    args = p.parse_args()

    preprocess_quarterly_data(
        do_winsor=args.winsor,
        do_seasonal=not args.no_seasonal,
        row_thresh=args.row_thresh,
    )


# from pathlib import Path
#
# import pandas as pd
# import numpy as np
# import re
# import os
# from statsmodels.tsa.seasonal import seasonal_decompose
# from statsmodels.tsa.stattools import adfuller
#
# from src.EA.data.mapping.column_mappings import quarterly_columns_map
#
#
# def load_and_map_quarterly_data(file_path: str) -> pd.DataFrame:
#     """
#     –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV —ñ–∑ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏ —ñ –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î –∫–æ–ª–æ–Ω–∫–∏ –∑–≥—ñ–¥–Ω–æ –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–æ–º quarterly_columns_map.
#     """
#     df = pd.read_csv(file_path, sep=',', decimal='.')
#     df.rename(columns=quarterly_columns_map, inplace=True)
#     return df
#
#
# def remove_duplicates_and_missing(df: pd.DataFrame) -> pd.DataFrame:
#     """
#     –í–∏–¥–∞–ª—è—î –¥—É–±–ª—ñ–∫–∞—Ç–∏ —ñ —Ä—è–¥–∫–∏ –∑ –ø—Ä–æ–ø—É—â–µ–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏.
#     """
#     df = df.drop_duplicates()
#     df = df.dropna()
#     return df
#
#
# def remove_outliers(df: pd.DataFrame, cols: list) -> pd.DataFrame:
#     """
#     –í–∏–¥–∞–ª—è—î —Ä—è–¥–∫–∏ –∑ –≤–∏–∫–∏–¥–∞–º–∏ –¥–ª—è –∑–∞–¥–∞–Ω–∏—Ö —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –∑–∞ –º–µ—Ç–æ–¥–æ–º IQR.
#     """
#     df_clean = df.copy()
#     for col in cols:
#         Q1 = df_clean[col].quantile(0.25)
#         Q3 = df_clean[col].quantile(0.75)
#         IQR = Q3 - Q1
#         lower_bound = Q1 - 1.5 * IQR
#         upper_bound = Q3 + 1.5 * IQR
#         df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
#     return df_clean
#
#
# def clean_numeric(x):
#     """
#     –û—á–∏—â–∞—î –≤—Ö—ñ–¥–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è, –∑–∞–ª–∏—à–∞—é—á–∏ –ª–∏—à–µ —Ü–∏—Ñ—Ä–∏ —Ç–∞ –¥–µ—Å—è—Ç–∫–æ–≤—É –∫—Ä–∞–ø–∫—É.
#     –Ø–∫—â–æ –≤ —Ä—è–¥–∫—É —î –∫–æ–º–∞ —è–∫ –¥–µ—Å—è—Ç–∫–æ–≤–∏–π —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫ (—ñ –Ω–µ–º–∞—î –∫—Ä–∞–ø–∫–∏),
#     –≤–æ–Ω–∞ –∑–∞–º—ñ–Ω—é—î—Ç—å—Å—è –Ω–∞ –∫—Ä–∞–ø–∫—É.
#     –Ø–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Ä–æ–∂–Ω—ñ–π ‚Äì –ø–æ–≤–µ—Ä—Ç–∞—î np.nan.
#     """
#     s = str(x).strip()
#     if ',' in s and '.' not in s:
#         s = s.replace(',', '.')
#     s_clean = re.sub(r"[^\d\.]", "", s)
#     return s_clean if s_clean != "" else np.nan
#
#
# def seasonal_adjustment(df: pd.DataFrame, date_col: str, value_col: str, period: int = 4,
#                         model: str = 'additive') -> pd.DataFrame:
#     """
#     –ó–∞—Å—Ç–æ—Å–æ–≤—É—î —Å–µ–∑–æ–Ω–Ω–∏–π —Ä–æ–∑–∫–ª–∞–¥ –¥–æ –∑–∞–¥–∞–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏ —á–∏—Å–ª–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–≥–æ DataFrame.
#     –î–æ–¥–∞—î –Ω–æ–≤—É –∫–æ–ª–æ–Ω–∫—É –∑—ñ —Å–µ–∑–æ–Ω–Ω–æ —Å–∫–æ—Ä–∏–≥–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏.
#
#     –ü–µ—Ä–µ–¥ –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è–º –∑–Ω–∞—á–µ–Ω–Ω—è –æ—á–∏—â–∞—é—Ç—å—Å—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é clean_numeric —ñ –∫–æ–Ω–≤–µ—Ä—Ç—É—é—Ç—å—Å—è –≤ —á–∏—Å–ª–æ.
#     –Ø–∫—â–æ –ø—ñ—Å–ª—è –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω—å –º–µ–Ω—à–∞ –∑–∞ period*2, –ø–æ–≤–µ—Ä—Ç–∞—î—Ç—å—Å—è –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è —ñ –¥–∞–Ω—ñ –±–µ–∑ —Å–µ–∑–æ–Ω–Ω–æ–≥–æ –∫–æ—Ä–∏–≥—É–≤–∞–Ω–Ω—è.
#
#     :param df: DataFrame, —â–æ –º—ñ—Å—Ç–∏—Ç—å —Å—Ç–æ–≤–ø–µ—Ü—å –¥–∞—Ç.
#     :param date_col: –Ü–º'—è –∫–æ–ª–æ–Ω–∫–∏ –∑ –¥–∞—Ç–∞–º–∏.
#     :param value_col: –Ü–º'—è —á–∏—Å–ª–æ–≤–æ–≥–æ —Å—Ç–æ–≤–ø—Ü—è –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ–≥–æ —Ä–æ–∑–∫–ª–∞–¥—É.
#     :param period: –°–µ–∑–æ–Ω–Ω–∞ –ø–µ—Ä—ñ–æ–¥–∏—á–Ω—ñ—Å—Ç—å (4 –¥–ª—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö).
#     :param model: –¢–∏–ø –º–æ–¥–µ–ª—ñ —Ä–æ–∑–∫–ª–∞–¥—É ('additive' –∞–±–æ 'multiplicative').
#     :return: DataFrame –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ—é –∫–æ–ª–æ–Ω–∫–æ—é value_col_seasonally_adjusted.
#     """
#     ts = df.copy()
#     ts[date_col] = pd.to_datetime(ts[date_col])
#     ts.set_index(date_col, inplace=True)
#
#     ts[value_col] = ts[value_col].astype(str).apply(clean_numeric)
#     ts[value_col] = pd.to_numeric(ts[value_col], errors='coerce')
#
#     # –ì—Ä—É–ø—É—î–º–æ –ª–∏—à–µ —Å—Ç–æ–≤–ø–µ—Ü—å value_col –¥–ª—è –∫–æ–∂–Ω–æ—ó –¥–∞—Ç–∏, –æ–±—á–∏—Å–ª—é—é—á–∏ —Å–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è
#     ts_value = ts[[value_col]].groupby(ts.index).mean()
#
#     # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —á–∞—Å—Ç–æ—Ç—É –∫–≤–∞—Ä—Ç–∞–ª—É.
#     # –ó–∞–º—ñ—Å—Ç—å –∑–∞—Å—Ç–∞—Ä—ñ–ª–æ–≥–æ 'S' –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ 's' (–ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ –¥–ª—è timestamp –≤—Å–µ –≥–∞—Ä–∞–∑–¥, –ø—Ä–æ—Ç–µ –¥–ª—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö —á–∞—Å—Ç–æ—Ç–∞ "QS" –±—ñ–ª—å—à–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å)
#     ts_value = ts_value.asfreq('QS')
#     ts_value.dropna(subset=[value_col], inplace=True)
#
#     if len(ts_value) < period * 2:
#         print(
#             f"–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω—å –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ–≥–æ —Ä–æ–∑–∫–ª–∞–¥—É (–Ω–µ–æ–±—Ö—ñ–¥–Ω–æ {period * 2}, –æ—Ç—Ä–∏–º–∞–Ω–æ {len(ts_value)}).")
#         ts_value[f"{value_col}_seasonally_adjusted"] = ts_value[value_col]
#         ts_value.reset_index(inplace=True)
#         df_out = pd.merge(df, ts_value[[date_col, f"{value_col}_seasonally_adjusted"]], on=date_col, how='left')
#         return df_out
#
#     result = seasonal_decompose(ts_value[value_col], model=model, period=period, extrapolate_trend='freq')
#
#     if model == 'additive':
#         sa_series = ts_value[value_col] - result.seasonal
#     elif model == 'multiplicative':
#         sa_series = ts_value[value_col] / result.seasonal
#     else:
#         raise ValueError("Model must be 'additive' or 'multiplicative'")
#
#     ts_value[f"{value_col}_seasonally_adjusted"] = sa_series
#     ts_value.reset_index(inplace=True)
#     df_out = pd.merge(df, ts_value[[date_col, f"{value_col}_seasonally_adjusted"]], on=date_col, how='left')
#     return df_out
#
#
# def check_stationarity(series: pd.Series, alpha: float = 0.05) -> (bool, float):
#     """
#     –ü–µ—Ä–µ–≤—ñ—Ä—è—î —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω—ñ—Å—Ç—å —á–∞—Å–æ–≤–æ—ó —Å–µ—Ä—ñ—ó –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Ç–µ—Å—Ç—É Augmented Dickey-Fuller.
#
#     :param series: –ß–∞—Å–æ–≤–∞ —Å–µ—Ä—ñ—è (pandas Series).
#     :param alpha: –†—ñ–≤–µ–Ω—å –∑–Ω–∞—á—É—â–æ—Å—Ç—ñ (0.05 –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º).
#     :return: –ö–æ—Ä—Ç–µ–∂ (is_stationary, p_value). –Ø–∫—â–æ —Å–µ—Ä—ñ—è –ø—É—Å—Ç–∞, –ø–æ–≤–µ—Ä—Ç–∞—î—Ç—å—Å—è (False, np.nan).
#     """
#     s = series.dropna()
#     if s.empty:
#         print("–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: –ß–∞—Å–æ–≤–∞ —Å–µ—Ä—ñ—è –ø–æ—Ä–æ–∂–Ω—è. –¢–µ—Å—Ç —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω–æ—Å—Ç—ñ –Ω–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è.")
#         return False, np.nan
#     result = adfuller(s)
#     p_value = result[1]
#     return (p_value < alpha), p_value
#
#
# def preprocess_quarterly_data():
#     # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
#     project_root = Path(__file__).resolve().parent.parent.parent.parent
#     out_dir = project_root / "research_data" / "import_data"
#     out_dir.mkdir(parents=True, exist_ok=True)
#     quarterly_data_path = out_dir / "imported_quarterly_data.csv"
#     df_quarterly = load_and_map_quarterly_data(quarterly_data_path)
#
#     # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ 'date', —Å—Ç–≤–æ—Ä–∏–º–æ —ó—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ 'quarter_period'
#     if 'date' not in df_quarterly.columns:
#         if 'quarter_period' in df_quarterly.columns:
#             df_quarterly['quarter_period'] = df_quarterly['quarter_period'].str.replace(" ", "")
#             # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ 's' –∑–∞–º—ñ—Å—Ç—å 'S'
#             df_quarterly['date'] = pd.PeriodIndex(df_quarterly['quarter_period'], freq='Q').to_timestamp('s')
#         else:
#             raise ValueError("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∏—Ö –¥–∞—Ç.")
#
#     # 2. –í–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ —Ç–∞ –ø—Ä–æ–ø—É—Å–∫—ñ–≤
#     df_clean = remove_duplicates_and_missing(df_quarterly)
#
#     # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ –¥–ª—è —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∫—Ä—ñ–º 'date')
#     numeric_cols = [col for col in df_clean.select_dtypes(include=[np.number]).columns if col != 'date']
#     df_clean = remove_outliers(df_clean, numeric_cols)
#
#     # 4. –°–µ–∑–æ–Ω–Ω–µ –∫–æ—Ä–∏–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –æ–±—Ä–∞–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏.
#     # –ü—Ä–∏–∫–ª–∞–¥: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É "real_gdp_index" (—è–∫—â–æ —Ç–∞–∫–∞ —ñ—Å–Ω—É—î)
#     if 'real_gdp_index' in df_clean.columns:
#         df_clean = seasonal_adjustment(df_clean, date_col='date', value_col='real_gdp_index', period=4,
#                                        model='additive')
#
#     # 5. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω–æ—Å—Ç—ñ –¥–ª—è —á–∞—Å–æ–≤–æ—ó —Å–µ—Ä—ñ—ó
#     ts = df_clean.copy()
#     ts['date'] = pd.to_datetime(ts['date'])
#     ts.set_index('date', inplace=True)
#     ts = ts[~ts.index.duplicated(keep='first')]
#     ts = ts.asfreq('QS')  # "QS" - –ø–æ—á–∞—Ç–æ–∫ –∫–≤–∞—Ä—Ç–∞–ª—É
#
#     col_to_test = "real_gdp_index_seasonally_adjusted" if "real_gdp_index_seasonally_adjusted" in ts.columns else "real_gdp_index"
#     if col_to_test in ts.columns:
#         is_stationary, p_val = check_stationarity(ts[col_to_test])
#         print(f"–°–µ—Ä—ñ—è '{col_to_test}' —î —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω–æ—é: {is_stationary} (p-value = {p_val:.4f})")
#     else:
#         print(f"–ö–æ–ª–æ–Ω–∫–∞ '{col_to_test}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω–æ—Å—Ç—ñ.")
#
#     # 6. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É —Ñ–∞–π–ª
#     output_dir = project_root / "research_data" / "preprocessed_data"
#     if not os.path.exists(output_dir):
#         os.makedirs(output_dir)
#     output_path = os.path.join(output_dir, "processed_quarterly_data.csv")
#     df_clean.to_csv(output_path, index=False)
#     print(f"–û–±—Ä–æ–±–ª–µ–Ω—ñ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–∞–π–ª: {output_path}")